{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6603e3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import mindspore as ms \n",
    "from mindnlp import core \n",
    "from mindspore import nn \n",
    "from peft import PeftModel, LoraConfig \n",
    "import numpy as np \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "class ModelServer:\n",
    "    def __init__(self, knowledge_base_path, api_url=\"http://localhost:8000/v1/chat/completions\"):\n",
    "        \"\"\"\n",
    "        初始化模型服务器\n",
    "        Args:\n",
    "            knowledge_base_path: 知识库文件路径\n",
    "            api_url: vLLM-MindSpore API 地址\n",
    "        \"\"\"\n",
    "        self.api_url = api_url\n",
    "\n",
    "        # 加载RAG知识库\n",
    "        with open(knowledge_base_path, 'r', encoding='utf-8') as f:\n",
    "            self.knowledge_base = json.load(f)\n",
    "        print(\"知识库加载完成！\")\n",
    "\n",
    "    def retrieve_knowledge(self, query, top_k=3):\n",
    "        \"\"\"向量检索 / 关键词检索（你可以替换成MindTinyRAG版本）\"\"\"\n",
    "        query_words = set(query.lower().split()) \n",
    "        results = []\n",
    "        for item in self.knowledge_base: \n",
    "            content = item[\"content\"].lower() \n",
    "            score = len(query_words.intersection(set(content.split()))) \n",
    "            if score > 0: \n",
    "                results.append((score, item)) \n",
    "        results.sort(key=lambda x: x[0], reverse=True) \n",
    "        return [item for _, item in results[:top_k]]\n",
    "\n",
    "    def generate_response(self, query, conversation_history=None, max_tokens=512, lora=\"sql-lora\"):\n",
    "        \"\"\"调用 vLLM-MindSpore API 生成回复\"\"\"\n",
    "\n",
    "        # 1. 检索相关知识\n",
    "        knowledge = self.retrieve_knowledge(query)\n",
    "\n",
    "        # 2. 构建系统提示\n",
    "        system_prompt = (\n",
    "            \"你是一个专业的北京旅游咨询助手，请严格根据提供的知识回答问题。\"\n",
    "            \"如果知识中没有提到，请回答“我在知识库中没有找到相关信息”。禁止编造。\"\n",
    "        )\n",
    "\n",
    "        knowledge_text = \"\\n\".join([f\"[知识{i+1}] {item['content']}\" for i, item in enumerate(knowledge)])\n",
    "\n",
    "        # 3. 构造对话上下文\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"相关知识:\\n{knowledge_text}\\n\\n用户问题: {query}\"}\n",
    "        ]\n",
    "\n",
    "        # 4. 请求 vLLM-MindSpore API\n",
    "        payload = {\n",
    "            \"model\": lora,   # 指定要用的 LoRA 模块\n",
    "            \"messages\": messages,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.9\n",
    "        }\n",
    "\n",
    "        response = requests.post(self.api_url, json=payload)\n",
    "        result = response.json()\n",
    "\n",
    "        # 5. 解析返回\n",
    "        answer = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "        return answer, knowledge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf68e9b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    server = ModelServer(knowledge_base_path=\"./knowledge_base.json\")\n",
    "\n",
    "    questions = [\n",
    "        \"你知道故宫的门票是多少钱吗？\",\n",
    "        \"北京的恭王府好不好？\",\n",
    "        \"恭王府的开放时间是什么时候？\",\n",
    "        \"天安门广场需要门票吗？\"\n",
    "    ]\n",
    "\n",
    "    for q in questions:\n",
    "        print(f\"\\n问题: {q}\")\n",
    "        answer, knowledge = server.generate_response(q)\n",
    "        print(\"回答:\", answer)\n",
    "        print(\"参考知识:\", [k[\"content\"][:50] for k in knowledge])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa623d07",
   "metadata": {},
   "source": [
    "python -m vllm_mindspore.entrypoints.vllm.entrypoints.openai.api_server \\\n",
    "    --model \"/home/ma-user/work/Qwen2.5-1.5B-Instruct/\" \\\n",
    "    --enable-lora \\\n",
    "    --lora-modules sql-lora=\"/home/ma-user/work/checkpoint-1300/\" \\\n",
    "    --port 8000\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
